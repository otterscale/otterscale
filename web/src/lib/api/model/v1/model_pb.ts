// @generated by protoc-gen-es v2.10.1 with parameter "target=ts"
// @generated from file api/model/v1/model.proto (package otterscale.model.v1, edition 2023)
/* eslint-disable */

import type { GenEnum, GenFile, GenMessage, GenService } from "@bufbuild/protobuf/codegenv2";
import { enumDesc, fileDesc, messageDesc, serviceDesc } from "@bufbuild/protobuf/codegenv2";
import { file_api_annotations } from "../../annotations_pb";
import type { Application_Pod } from "../../application/v1/application_pb";
import { file_api_application_v1_application } from "../../application/v1/application_pb";
import type { EmptySchema, Timestamp } from "@bufbuild/protobuf/wkt";
import { file_google_protobuf_empty, file_google_protobuf_timestamp } from "@bufbuild/protobuf/wkt";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file api/model/v1/model.proto.
 */
export const file_api_model_v1_model: GenFile = /*@__PURE__*/
  fileDesc("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", [file_api_annotations, file_api_application_v1_application, file_google_protobuf_empty, file_google_protobuf_timestamp]);

/**
 * @generated from message otterscale.model.v1.Model
 */
export type Model = Message<"otterscale.model.v1.Model"> & {
  /**
   * @generated from field: string id = 1;
   */
  id: string;

  /**
   * @generated from field: string name = 11;
   */
  name: string;

  /**
   * @generated from field: string namespace = 12;
   */
  namespace: string;

  /**
   * @generated from field: string status = 13;
   */
  status: string;

  /**
   * @generated from field: string description = 14;
   */
  description: string;

  /**
   * @generated from field: google.protobuf.Timestamp first_deployed_at = 15;
   */
  firstDeployedAt?: Timestamp;

  /**
   * @generated from field: google.protobuf.Timestamp last_deployed_at = 16;
   */
  lastDeployedAt?: Timestamp;

  /**
   * @generated from field: string chart_version = 21;
   */
  chartVersion: string;

  /**
   * @generated from field: string app_version = 22;
   */
  appVersion: string;

  /**
   * @generated from field: otterscale.model.v1.Model.Mode mode = 31;
   */
  mode: Model_Mode;

  /**
   * disabled if mode is intelligent inference scheduling
   *
   * @generated from field: otterscale.model.v1.Model.Prefill prefill = 32;
   */
  prefill?: Model_Prefill;

  /**
   * @generated from field: otterscale.model.v1.Model.Decode decode = 33;
   */
  decode?: Model_Decode;

  /**
   * @generated from field: uint32 max_model_length = 34;
   */
  maxModelLength: number;

  /**
   * @generated from field: repeated otterscale.application.v1.Application.Pod pods = 41;
   */
  pods: Application_Pod[];

  /**
   * @generated from field: bool from_persistent_volume_claim = 51;
   */
  fromPersistentVolumeClaim: boolean;

  /**
   * @generated from field: string persistent_volume_claim_name = 52;
   */
  persistentVolumeClaimName: string;
};

/**
 * Describes the message otterscale.model.v1.Model.
 * Use `create(ModelSchema)` to create a new message.
 */
export const ModelSchema: GenMessage<Model> = /*@__PURE__*/
  messageDesc(file_api_model_v1_model, 0);

/**
 * @generated from message otterscale.model.v1.Model.Prefill
 */
export type Model_Prefill = Message<"otterscale.model.v1.Model.Prefill"> & {
  /**
   * @generated from field: uint32 replica = 1;
   */
  replica: number;

  /**
   * @generated from field: uint32 tensor = 2;
   */
  tensor: number;

  /**
   * @generated from field: uint32 vgpumem_percentage = 11;
   */
  vgpumemPercentage: number;
};

/**
 * Describes the message otterscale.model.v1.Model.Prefill.
 * Use `create(Model_PrefillSchema)` to create a new message.
 */
export const Model_PrefillSchema: GenMessage<Model_Prefill> = /*@__PURE__*/
  messageDesc(file_api_model_v1_model, 0, 0);

/**
 * @generated from message otterscale.model.v1.Model.Decode
 */
export type Model_Decode = Message<"otterscale.model.v1.Model.Decode"> & {
  /**
   * set to 1 if mode is prefill-decode disaggregation
   *
   * @generated from field: uint32 replica = 1;
   */
  replica: number;

  /**
   * @generated from field: uint32 tensor = 2;
   */
  tensor: number;

  /**
   * @generated from field: uint32 vgpumem_percentage = 11;
   */
  vgpumemPercentage: number;
};

/**
 * Describes the message otterscale.model.v1.Model.Decode.
 * Use `create(Model_DecodeSchema)` to create a new message.
 */
export const Model_DecodeSchema: GenMessage<Model_Decode> = /*@__PURE__*/
  messageDesc(file_api_model_v1_model, 0, 1);

/**
 * @generated from enum otterscale.model.v1.Model.Mode
 */
export enum Model_Mode {
  /**
   * @generated from enum value: MODE_INTELLIGENT_INFERENCE_SCHEDULING = 0;
   */
  INTELLIGENT_INFERENCE_SCHEDULING = 0,

  /**
   * heterogeneous parallelism
   *
   * @generated from enum value: MODE_PREFILL_DECODE_DISAGGREGATION = 1;
   */
  PREFILL_DECODE_DISAGGREGATION = 1,
}

/**
 * Describes the enum otterscale.model.v1.Model.Mode.
 */
export const Model_ModeSchema: GenEnum<Model_Mode> = /*@__PURE__*/
  enumDesc(file_api_model_v1_model, 0, 0);

/**
 * @generated from message otterscale.model.v1.ListModelsRequest
 */
export type ListModelsRequest = Message<"otterscale.model.v1.ListModelsRequest"> & {
  /**
   * @generated from field: string scope = 1;
   */
  scope: string;

  /**
   * @generated from field: string namespace = 3;
   */
  namespace: string;
};

/**
 * Describes the message otterscale.model.v1.ListModelsRequest.
 * Use `create(ListModelsRequestSchema)` to create a new message.
 */
export const ListModelsRequestSchema: GenMessage<ListModelsRequest> = /*@__PURE__*/
  messageDesc(file_api_model_v1_model, 1);

/**
 * @generated from message otterscale.model.v1.ListModelsResponse
 */
export type ListModelsResponse = Message<"otterscale.model.v1.ListModelsResponse"> & {
  /**
   * @generated from field: repeated otterscale.model.v1.Model models = 1;
   */
  models: Model[];

  /**
   * @generated from field: string service_uri = 2;
   */
  serviceUri: string;
};

/**
 * Describes the message otterscale.model.v1.ListModelsResponse.
 * Use `create(ListModelsResponseSchema)` to create a new message.
 */
export const ListModelsResponseSchema: GenMessage<ListModelsResponse> = /*@__PURE__*/
  messageDesc(file_api_model_v1_model, 2);

/**
 * @generated from message otterscale.model.v1.CreateModelRequest
 */
export type CreateModelRequest = Message<"otterscale.model.v1.CreateModelRequest"> & {
  /**
   * @generated from field: string scope = 1;
   */
  scope: string;

  /**
   * @generated from field: string namespace = 3;
   */
  namespace: string;

  /**
   * @generated from field: string name = 4;
   */
  name: string;

  /**
   * @generated from field: string model_name = 11;
   */
  modelName: string;

  /**
   * @generated from field: uint64 size_bytes = 12;
   */
  sizeBytes: bigint;

  /**
   * @generated from field: bool from_persistent_volume_claim = 13;
   */
  fromPersistentVolumeClaim: boolean;

  /**
   * @generated from field: string persistent_volume_claim_name = 14;
   */
  persistentVolumeClaimName: string;

  /**
   * @generated from field: otterscale.model.v1.Model.Mode mode = 21;
   */
  mode: Model_Mode;

  /**
   * @generated from field: otterscale.model.v1.Model.Prefill prefill = 22;
   */
  prefill?: Model_Prefill;

  /**
   * @generated from field: otterscale.model.v1.Model.Decode decode = 23;
   */
  decode?: Model_Decode;

  /**
   * @generated from field: uint32 max_model_length = 24;
   */
  maxModelLength: number;
};

/**
 * Describes the message otterscale.model.v1.CreateModelRequest.
 * Use `create(CreateModelRequestSchema)` to create a new message.
 */
export const CreateModelRequestSchema: GenMessage<CreateModelRequest> = /*@__PURE__*/
  messageDesc(file_api_model_v1_model, 3);

/**
 * @generated from message otterscale.model.v1.UpdateModelRequest
 */
export type UpdateModelRequest = Message<"otterscale.model.v1.UpdateModelRequest"> & {
  /**
   * @generated from field: string scope = 1;
   */
  scope: string;

  /**
   * @generated from field: string namespace = 3;
   */
  namespace: string;

  /**
   * @generated from field: string name = 4;
   */
  name: string;

  /**
   * @generated from field: otterscale.model.v1.Model.Mode mode = 21;
   */
  mode: Model_Mode;

  /**
   * @generated from field: otterscale.model.v1.Model.Prefill prefill = 22;
   */
  prefill?: Model_Prefill;

  /**
   * @generated from field: otterscale.model.v1.Model.Decode decode = 23;
   */
  decode?: Model_Decode;

  /**
   * @generated from field: uint32 max_model_length = 24;
   */
  maxModelLength: number;
};

/**
 * Describes the message otterscale.model.v1.UpdateModelRequest.
 * Use `create(UpdateModelRequestSchema)` to create a new message.
 */
export const UpdateModelRequestSchema: GenMessage<UpdateModelRequest> = /*@__PURE__*/
  messageDesc(file_api_model_v1_model, 4);

/**
 * @generated from message otterscale.model.v1.DeleteModelRequest
 */
export type DeleteModelRequest = Message<"otterscale.model.v1.DeleteModelRequest"> & {
  /**
   * @generated from field: string scope = 1;
   */
  scope: string;

  /**
   * @generated from field: string namespace = 3;
   */
  namespace: string;

  /**
   * @generated from field: string name = 4;
   */
  name: string;
};

/**
 * Describes the message otterscale.model.v1.DeleteModelRequest.
 * Use `create(DeleteModelRequestSchema)` to create a new message.
 */
export const DeleteModelRequestSchema: GenMessage<DeleteModelRequest> = /*@__PURE__*/
  messageDesc(file_api_model_v1_model, 5);

/**
 * @generated from message otterscale.model.v1.ModelArtifact
 */
export type ModelArtifact = Message<"otterscale.model.v1.ModelArtifact"> & {
  /**
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * @generated from field: string namespace = 2;
   */
  namespace: string;

  /**
   * @generated from field: string model_name = 11;
   */
  modelName: string;

  /**
   * @generated from field: string phase = 21;
   */
  phase: string;

  /**
   * @generated from field: int64 size = 22;
   */
  size: bigint;

  /**
   * @generated from field: string volume_name = 31;
   */
  volumeName: string;

  /**
   * @generated from field: google.protobuf.Timestamp created_at = 41;
   */
  createdAt?: Timestamp;
};

/**
 * Describes the message otterscale.model.v1.ModelArtifact.
 * Use `create(ModelArtifactSchema)` to create a new message.
 */
export const ModelArtifactSchema: GenMessage<ModelArtifact> = /*@__PURE__*/
  messageDesc(file_api_model_v1_model, 6);

/**
 * @generated from message otterscale.model.v1.ListModelArtifactsRequest
 */
export type ListModelArtifactsRequest = Message<"otterscale.model.v1.ListModelArtifactsRequest"> & {
  /**
   * @generated from field: string scope = 1;
   */
  scope: string;

  /**
   * @generated from field: string namespace = 3;
   */
  namespace: string;
};

/**
 * Describes the message otterscale.model.v1.ListModelArtifactsRequest.
 * Use `create(ListModelArtifactsRequestSchema)` to create a new message.
 */
export const ListModelArtifactsRequestSchema: GenMessage<ListModelArtifactsRequest> = /*@__PURE__*/
  messageDesc(file_api_model_v1_model, 7);

/**
 * @generated from message otterscale.model.v1.ListModelArtifactsResponse
 */
export type ListModelArtifactsResponse = Message<"otterscale.model.v1.ListModelArtifactsResponse"> & {
  /**
   * @generated from field: repeated otterscale.model.v1.ModelArtifact model_artifacts = 1;
   */
  modelArtifacts: ModelArtifact[];
};

/**
 * Describes the message otterscale.model.v1.ListModelArtifactsResponse.
 * Use `create(ListModelArtifactsResponseSchema)` to create a new message.
 */
export const ListModelArtifactsResponseSchema: GenMessage<ListModelArtifactsResponse> = /*@__PURE__*/
  messageDesc(file_api_model_v1_model, 8);

/**
 * @generated from message otterscale.model.v1.CreateModelArtifactRequest
 */
export type CreateModelArtifactRequest = Message<"otterscale.model.v1.CreateModelArtifactRequest"> & {
  /**
   * @generated from field: string scope = 1;
   */
  scope: string;

  /**
   * @generated from field: string namespace = 3;
   */
  namespace: string;

  /**
   * @generated from field: string name = 4;
   */
  name: string;

  /**
   * @generated from field: string model_name = 11;
   */
  modelName: string;

  /**
   * @generated from field: int64 size = 12;
   */
  size: bigint;
};

/**
 * Describes the message otterscale.model.v1.CreateModelArtifactRequest.
 * Use `create(CreateModelArtifactRequestSchema)` to create a new message.
 */
export const CreateModelArtifactRequestSchema: GenMessage<CreateModelArtifactRequest> = /*@__PURE__*/
  messageDesc(file_api_model_v1_model, 9);

/**
 * @generated from message otterscale.model.v1.DeleteModelArtifactRequest
 */
export type DeleteModelArtifactRequest = Message<"otterscale.model.v1.DeleteModelArtifactRequest"> & {
  /**
   * @generated from field: string scope = 1;
   */
  scope: string;

  /**
   * @generated from field: string namespace = 3;
   */
  namespace: string;

  /**
   * @generated from field: string name = 4;
   */
  name: string;
};

/**
 * Describes the message otterscale.model.v1.DeleteModelArtifactRequest.
 * Use `create(DeleteModelArtifactRequestSchema)` to create a new message.
 */
export const DeleteModelArtifactRequestSchema: GenMessage<DeleteModelArtifactRequest> = /*@__PURE__*/
  messageDesc(file_api_model_v1_model, 10);

/**
 * @generated from service otterscale.model.v1.ModelService
 */
export const ModelService: GenService<{
  /**
   * @generated from rpc otterscale.model.v1.ModelService.ListModels
   */
  listModels: {
    methodKind: "unary";
    input: typeof ListModelsRequestSchema;
    output: typeof ListModelsResponseSchema;
  },
  /**
   * @generated from rpc otterscale.model.v1.ModelService.CreateModel
   */
  createModel: {
    methodKind: "unary";
    input: typeof CreateModelRequestSchema;
    output: typeof ModelSchema;
  },
  /**
   * @generated from rpc otterscale.model.v1.ModelService.UpdateModel
   */
  updateModel: {
    methodKind: "unary";
    input: typeof UpdateModelRequestSchema;
    output: typeof ModelSchema;
  },
  /**
   * @generated from rpc otterscale.model.v1.ModelService.DeleteModel
   */
  deleteModel: {
    methodKind: "unary";
    input: typeof DeleteModelRequestSchema;
    output: typeof EmptySchema;
  },
  /**
   * @generated from rpc otterscale.model.v1.ModelService.ListModelArtifacts
   */
  listModelArtifacts: {
    methodKind: "unary";
    input: typeof ListModelArtifactsRequestSchema;
    output: typeof ListModelArtifactsResponseSchema;
  },
  /**
   * @generated from rpc otterscale.model.v1.ModelService.CreateModelArtifact
   */
  createModelArtifact: {
    methodKind: "unary";
    input: typeof CreateModelArtifactRequestSchema;
    output: typeof ModelArtifactSchema;
  },
  /**
   * @generated from rpc otterscale.model.v1.ModelService.DeleteModelArtifact
   */
  deleteModelArtifact: {
    methodKind: "unary";
    input: typeof DeleteModelArtifactRequestSchema;
    output: typeof EmptySchema;
  },
}> = /*@__PURE__*/
  serviceDesc(file_api_model_v1_model, 0);

